# 一、中文开源表征模型训练

基于收集到的公开语义相似数据集训练调优通用+专用表征模型，具体工作有：

1. 构建评测表征模型效果的 benchmark
2. 各个数据集之间互补增益分析
3. 优化通用和专用领域表征模型

## 1.1 benchmark

| 评测集                 | 大小  | 类型          |
| ---------------------- | ----- | ------------- |
| **Chinese-STS-B-dev**  | 1458  | label=0.0~1.0 |
| **Chinese-STS-B-test** | 1361  | label=0.0~1.0 |
| **afqmc-dev**          | 4316  | label=0,1     |
| **lcqmc-dev**          | 8802  | label=0,1     |
| **bqcorpus-dev**       | 10000 | label=0,1     |
| **pawsx_dev**          | 2000  | label=0,1     |
| **oppo-xiaobu-dev**    | 10000 | label=0,1     |

## 1.2 数据集互补增益

为了更好的利用开源数据集，训练领域通用和专用语义表征模型，对各个开源数据集上训练得到的模型分析其在不同任务上 **zero-shot** 的效果。参照[Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)的工作迭代思路，对以上数据集进行训练。由于以上各个数据集的数据形式不同，分别选取了不同优化目标（并不一定是最好的优化目标）进行 fine-tune 训练：

| Task | Datasets                                    | Loss                                                         | Desc                                    |
| ---- | ------------------------------------------- | ------------------------------------------------------------ | --------------------------------------- |
| STS  | STS-B-Chinese                               | [CosineSimilarityLoss](https://www.sbert.net/docs/package_reference/losses.html#cosinesimilarityloss) | 向量相似性度量损失                      |
| NLI  | OCNLI; CSNLI, CMNLI                         | [SoftmaxLoss](https://www.sbert.net/docs/package_reference/losses.html#softmaxloss) | 分类交叉熵                              |
| QMC  | LCQMC, AFQMC, BQCorpus, PAWS-X, OPPO-xiaobu | [OnlineContrastiveLoss](https://www.sbert.net/docs/package_reference/losses.html#onlinecontrastiveloss) | 正例近&负例远                           |
| QMC  | PKU-Paraphrase-Bank                         | [MultipleNegativesRankingLoss](https://www.sbert.net/docs/package_reference/losses.html#multiplenegativesrankingloss) | 仅正例对，batch内构造负例（可选难负例） |

**zero-short: 评测任务之间互补收益**

![](/Users/shaw/Documents/code/embeddings/resources/task_corr.png)

*上图：对比各个任务上训练得到的模型在其它任务的评测集上效果（行是模型，列是任务）；效果基于模型计算的语句对向量相似性跟真实标签之间的 spearman 系数，其中 NLI 分类数据集的真实标签进行了 0.0~1.0 归一化处理；其中 bert-mean 表示直接拿 BERT 均值池化得到语句向量的效果*

对上述各个任务之间的相互评测结果**分析结论**有：

**（1）从评测任务角度来看：**

| 效果     | 任务            | 分析                                                         |
| -------- | --------------- | ------------------------------------------------------------ |
| Good     | csts            | 除 pawsx 和 qbqtc 外，其它模型效果都较好。一方面 csts 语料较为通用，另一方面评测集规模 1k 左右，相对来说任务难度较低。 |
| Good     | lcqmc           | 除 pawsx、qbqtc、pkuparaph 外，其它模型效果都较好。主要原因在于 lcqmc 是从百度知道多个话题领域收集的通用 QMC 数据集，不同任务上训练的模型都对 lcqmc 有增益。 |
| Good     | xiaobu          | 除 pawsx、qbqtc、pkuparaph 外，其它模型效果都较好。主要原因在于 oppo-xiao 是 oppo 小布对话助手在开放领域的对话语料，不同任务上训练的模型都对 xiaobu 有增益。 |
| Bad      | pawsx           | 除了 pawsx 自己，其它模型效果都较差。pawsx 任务重点考察对句法结构的理解能力，对 BERT 模型来说相对较难，且跟其它语义匹配任务存在一定差异。 |
| Bad      | nli*            | 除了 ocnli/cmnli/csnli 数据集彼此之间，其它模型在这类 NLI 评测集上效果较差。NLI 数据集跟 STS/QMC 这类语义相似数据还是有差异的，**不适合直接拉齐对比**。 |
| Bad/Good | afqmc /bqcorpus | afqmc 任务上，只有 bqcorpus 和 lcqmc 模型的效果还相对不是很差，主要因为 afqmc 语料领域更为专一（限定在蚂蚁金服业务场景），其它通用领域的模型在上面效果较为一般。不过 bqcorpus 虽然也是金融领域 qmc，但语料场景相对宽泛，所以很多模型在 bqcorpus 评测集上效果都较好。 |

- 在通用场景的语义匹配任务上（如 csts、lcqmc、xiaobu等），大多模型 zero-shot 效果不错，因此只要调优过的表征模型在通用场景下效果不会太差
- 在专用领域场景下（如 afqmc），大多模型 zero-shot 效果不佳，因此专用领域应该适配专用模型
- 在较难的任务场景下（如 pawsx、qbqtc），大多模型 zero-shot 效果较差，因此特征任务场景就需要投入人力深入去优化

**（2）从模型角度来看**

| 效果 | 模型            | 分析                                                         |
| ---- | --------------- | ------------------------------------------------------------ |
| Good | csts            | csts 模型对大多任务都有正向贡献。                            |
| Good | nli*            | 除了 pawsx、afqmc 外，nli 类模型对大多任务都有正向贡献。NLI 数据集的语料较为通用，训练的模型可以适用于多个领域。 |
| Good | lcqmc           | lcqmc 模型对大多任务都有正向贡献，且效果较为显著。           |
| Good | xiaobu          | xiaobu 模型对大多任务都有正向贡献。                          |
| Good | afqmc和bqcorpus | afqmc和bqcorpus 对大多任务都有正向贡献。金融领域两个 qmc 任务之间存在互补，且 afqmc 模型在 bqcorpus 任务上效果较好（bqcorpus 任务更容易）。 |
| Good | pkuparaph       | pkuparaph 模型对大多任务都有正向贡献。                       |
| Bad  | pawsx           | 对其它任务贡献有限。                                         |
| Bad  | qbqtc           | 对其它任务贡献有限。                                         |

- csts、nli*、pkuparaph、pawsx 数据集作为**跨领域**通用基础数据集，具体使用方式是采用 **nli+pkuparaph+pawsx -> sts** 的串行方式来训练（模型简写为 model-v0）
- **lcqmc** 数据集作为**问题匹配领域**（QMC）通用基础数据集，以 model-v0 为起点来在该数据集上调优得到 model-v0-1
- **xiaobu** 数据集作为**对话匹配领域**（DTM）通用基础数据集，以 model-v0 为起点来在该数据集上调优得到 model-v0-2
- **bqcorpus** 数据集作为**金融领域问题匹配**数据集，以 model-v0-v1 为起点来在这两个混合数据集上调优得到 model-v0-1-1

## 1.3 表征模型优化

### 1.3.1 通用领域模型

结合上述数据集之间互补增益的分析，针对通用领域的开源数据集（nli+pkuparaph+pawsx+sts），有以下几种串行训练模型的方式：

**方式一**、仅保留nli数据：nli -> sts

|                    | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| ------------------ | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts**(baseline) | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **allnlizh**       | 82.74%       | 80.61%        | 22.04%     | 65.09%     | **44.32%**   | 10.25%     | 48.72%     |
| **csts_allnlizh**  | **84.81%**   | **81.84%**    | **22.55%** | **65.84%** | 42.45%       | **12.14%** | **49.52%** |

*在 nli 数据集上训练后，模型效果已经有较大幅度提升，再使用 sts 数据训练会有大约 1% 左右提升*

**方式二**、从难到易：pawsx -> pkuparaph -> nli -> sts（`general-best`）

|                                   | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| --------------------------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts**(baseline)                | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **pawsx**                         | 48.14%       | 41.77%        | 16.95%     | 39.29%     | 36.83%       | **54.62%** | 34.01%     |
| **pkuparaph_pawsx**               | 75.93%       | 68.31%        | 18.97%     | 50.87%     | 44.78%       | 6.17%      | 36.21%     |
| **allnlizh_pkuparaph_pawsx**      | 82.88%       | 80.74%        | 24.31%     | 63.84%     | **46.46%**   | 10.75%     | 48.03%     |
| **csts_allnlizh_pkuparaph_pawsx** | **84.54%**   | **82.17%**    | **23.80%** | **65.94%** | 45.52%       | 11.52%     | **48.51%** |

*引入 paws、pku- paraphrase-bank 以及 nli 数据集，以由难到易串行方式训练，除了在 pawsx 任务上外，其它效果几乎都是最好的*

**方式三**、从易到难：nli -> pkuparaph-> pawsx -> sts

|                                   | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| --------------------------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts**(baseline)                | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **allnlizh**                      | **82.74%**   | **80.61%**    | **22.04%** | **65.09%** | 44.32%       | 10.25%     | **48.72%** |
| **pkuparaph_allnlizh**            | 80.70%       | 74.19%        | 21.15%     | 53.08%     | 46.50%       | 4.79%      | 38.77%     |
| **pawsx_pkuparaph_allnlizh**      | 46.40%       | 40.74%        | 17.74%     | 38.86%     | 38.50%       | **54.13%** | 34.67%     |
| **csts_pawsx_pkuparaph_allnlizh** | 81.13%       | 77.79%        | 21.75%     | 62.26%     | **47.15%**   | 37.10%     | 44.60%     |

*引入 paws、pku- paraphrase-bank 以及 nli 数据集，以由易到难串行方式训练，除了在 pawsx 任务外，几乎全面落败于方式一*

**方式四**、正样本对混合：nli+pkuparaph+pawsx -> sts

|                     | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx** | **xiaobu** |
| ------------------- | ------------ | ------------- | ---------- | ---------- | ------------ | --------- | ---------- |
| **csts**            | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%     | 42.46%     |
| **allpospair**      | 80.72%       | 76.18%        | 18.02%     | 59.18%     | 42.00%       | 6.67%     | 44.92%     |
| **csts_allpospair** | **84.45%**   | **81.37%**    | **20.50%** | **61.67%** | **44.57%**   | **8.41%** | **46.38%** |

*将 paws、pku- paraphrase-bank 以及 nli 数据集中的所有正样本对抽取出来，在其上训练模型，全面落败于方式一*

**小结**：

- 从难到易串行训练模型是目前最佳方案（`general-best`）
- 仅依靠 NLI 数据集已经可以取得不错的效果
- PAWS-X 任务较难，只有单独拟合该数据集时效果才尚可接受
- 抽取所有正样本对进行混合训练并没有取得额外收益，可能由于 NLI 负例被丢弃

### 1.3.2 通用领域模型-SimCLUE

除了上述方式外，我们还可以利用**大规模的语义相似数据集 SimCLUE** 来训练通用领域模型。[SimCLUE](https://github.com/CLUEbenchmark/SimCLUE) 整合了中文领域绝大多数可用的开源的语义相似度和自然语言推理的数据集（涵盖上述我们收集的大多数数据集），并重新做了数据拆分和整理。因此可以作为通用语义数据集，用于训练中文通用语义表征模型。

根据 SimCLUE 提供的数据形式，可以通过以下几种方式进行 fine-tune 训练：

| 方式           | 数据形式                                 | 简介                                                      | 优化    |
| -------------- | ---------------------------------------- | --------------------------------------------------------- | ------- |
| **simclue-v1** | `Pair(sentence1, sentence2) + label=0,1` | sentence1和sentence2之间的语义由label定义（1相同，0不同） | qmc     |
| **simclue-v2** | `Pair(sentence1, sentence2)`             | 仅含上述pair数据集中语义相同的sentence1和sentence2        | rank    |
| **simclue-v3** | `Triplet(query, title, neg_title)`       | query和title语义一致，query和neg_title语义不同            | rank    |
| **simclue-v4** | `Triplet(query, title, neg_title)`       | query和title语义一致，query和neg_title语义不同            | triplet |

在各个任务上的**效果**如下：

|                  | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** | **simclue_dev** | **simclue_test** |
| ---------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- | --------------- | ---------------- |
| **csts-base**    | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.06%      | 42.46%     | 36.50%          | 43.47%           |
| **general-best** | **84.54%**   | **82.17%**    | 23.80%     | 65.94%     | 45.52%       | 11.52%     | 48.51%     | 47.66%          | 53.02%           |
| **simclue-v1**   | 77.20%       | 72.60%        | **36.80%** | **76.92%** | 49.63%       | **16.24%** | **63.16%** | **72.72%**      | **73.89%**       |
| **simclue-v2**   | 80.06%       | 74.21%        | 33.38%     | 61.39%     | 51.41%       | 7.33%      | 53.36%     | 46.68%          | 51.33%           |
| **simclue-v3**   | 82.30%       | 77.37%        | 29.78%     | 63.41%     | **51.64%**   | 8.68%      | 53.72%     | 49.32%          | 54.86%           |
| **simclue-v4**   | 80.21%       | 75.81%        | 26.66%     | 61.89%     | 48.10%       | 7.71%      | 52.92%     | 46.83%          | 52.45%           |

- 这里 `general-best` 即上述从难到易串行训练得到的最佳模型
- 最优模型是 `simclue_v1`，在各个任务上表现都较好，跟 `general-best` 对比可以发现后者在 sts 数据集上存在过拟合的现象
- 模型 `simclue_v3` 基于 MNRL loss 优化，大量实验验证了该优化目标效果会更好，但这里结果不符合预期，后续可分析优化

### 1.3.3 开放领域问题匹配模型

加载通用领域预训练模型在**问题匹配**（QMC）场景下进行训练：

|                   | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| ----------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts-base**     | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **general-best**  | **84.55%**   | **82.17%**    | 23.80%     | 65.94%     | 45.52%       | 11.52%     | 48.51%     |
| **simclue-v1**   | 77.20%       | 72.60%        | **36.80%** | 76.92% | 49.63%       | **16.24%** | **63.16%** |
| **qmc-base**      | 78.42%       | 74.08%        | 32.20%     | **79.68%** | 52.32%       | 9.50%      | 51.26%     |
| **qmc-domain-v1** | 83.08%       | 79.85%        | 29.49%     | 78.05%     | 50.61%       | 10.71%     | 49.38%     |
| **qmc-domain-v2** | 80.67%       | 77.58%        | 29.67%     | 77.80%     | 51.70%       | 11.83%     | 50.48%     |
| **qmc-domain-v3** | 80.90%       | 76.63%        | 34.51% | 77.06%     | **52.96%**   | 12.98% | 59.48% |

*其中 csts-base 是基于 csts 数据集训练的模型；general-best 是调优过最好的通用领域模型；qmc-base 是基于 qmc 数据集训练的模型；qmc-domain-v1 是加载 general-best 训练的模型；qmc-domain-v2 是加载 nli 训练的模型；qmc-domain-v3 是加载 simclue-v1 训练的模型；以上 QMC 训练数据来自 lcqmc；*

TODO：

- 综合多个 QMC 任务（afqmc/lcqmc/bqcorpus）来看 `qmc-domain-v3` 效果更优
- 引入更多开源问题匹配数据集来验证效果

### 1.3.4 开放领域对话匹配模型

加载通用领域的预训练模型，然后继续在**对话短文本匹配**（DSTM）场景下进行训练：

|                   | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| ----------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts-base**     | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **general-best**  | **84.55%**   | **82.17%**    | 23.80%     | 65.94%     | 45.52%   | 11.52%     | 48.51%     |
| **simclue-v1**   | 77.20%       | 72.60%        | **36.80%** | **76.92%** | **49.63%**   | **16.24%** | 63.16% |
| **dtm-base**      | 74.23%       | 68.37%        | 25.87%     | 70.46%     | 42.23%       | 9.76%      | **68.08%** |
| **dtm-domain-v1** | 80.63%       | 75.62%        | 22.72%     | 66.57%     | 39.86%       | 11.97%     | 65.74%     |
| **dtm-domain-v2** | 79.12%       | 74.20%        | 25.52%     | 68.86%     | 41.88%       | 12.39%     | 65.65%     |
| **dtm-domain-v3** | 78.36%       | 74.46%        | 32.18% | 75.95% | 44.01%       | 14.50% | 66.85%     |

*其中 csts-base 是基于 csts 数据集训练的模型；general-best 是调优过最好的通用领域模型；dtm-base 是基于 dtm 数据集训练的模型；dtm-domain-v1 是加载 general-best 训练的模型；dtm-domain-v2 是加载 nli 训练的模型；dtm-domain-v3 是加载 simclue-v1 训练的模型；以上 DTM 训练数据来自 oppo-xiaobu*

TODO：

- 综合 pawsx/xiaobu 任务来看 `dtm-domain-v3` 效果更优
- 引入更多开源对话匹配数据集来验证效果

### 1.3.5 金融领域问题匹配模型

加载开放领域问题匹配的预训练模型，然后继续在**金融领域的问题匹配**（FQMC）场景下进行训练：

|                   | **csts_dev** | **csts_test** | **afqmc**  | **lcqmc**  | **bqcorpus** | **pawsx**  | **xiaobu** |
| ----------------- | ------------ | ------------- | ---------- | ---------- | ------------ | ---------- | ---------- |
| **csts-base**     | 81.54%       | 76.14%        | 16.68%     | 58.18%     | 39.73%       | 6.07%      | 42.46%     |
| **general-best**  | **84.55%**   | **82.17%**    | 23.80%     | 65.94%     | 45.52%       | 11.52%     | 48.51%     |
| **simclue-v1**   | 77.20%       | 72.60%        | **36.80%** | **76.92%** | 49.63%   | **16.24%** | **63.16%** |
| **fin-base**      | 66.85%       | 61.52%        | 34.62%     | 59.15%     | **74.06%**   | 7.51%      | 42.97%     |
| **fin-domain-v1** | 78.16%       | 75.05%        | 33.96%     | 73.81%     | 73.59%       | 11.00%     | 45.55%     |
| **fin-domain-v2** | 76.69%       | 72.92%        | 34.63%     | 74.15%     | 73.97%       | 11.10%     | 46.52%     |
| **fin-domain-v3** | 77.40%       | 74.55%        | 36.01% | 75.75% | 73.25%       | 11.58% | 54.76% |

*其中 csts-base 是基于 csts 数据集训练的模型；general-best 是调优过最好的通用领域模型；fin-base 是基于 fin-qmc 数据集训练的模型；fin-domain-v1 是加载 general-best 训练的模型；fin-domain-v2 是加载 nli 训练的模型；fin-domain-v3 是加载 simclue-v1 训练的模型；以上 FQMC 训练数据来自 bqcorpus 数据集；*

TODO：

- 综合多个 FQMC 任务（afqmc/bqcorpus）来看 `fin-domain-v3` 效果更优
- 引入更多开源金融问题匹配数据集来验证效果

